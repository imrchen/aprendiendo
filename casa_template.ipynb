{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "casa - template.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YRrokW6YsATH"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPU+x8xeHkRWoOGgI4rGF/f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imrchen/aprendiendo/blob/master/casa_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P50EDCecWym7"
      },
      "source": [
        "# My Template\n",
        "\n",
        "- actualizado en el <font size=6 color=\"firebrick\">seis de agosto</font> de **<u>2021</u>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELHbG3KEfZSI"
      },
      "source": [
        "## Most frequently used packages (imports) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMZB-fZkIN_u"
      },
      "source": [
        "- [Pandas Options and settings](https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html)\n",
        "- [pandas.set_options](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.set_option.html?highlight=set_option#pandas.set_option)\n",
        "- [Customizing Matplotlib with style sheets and rcParams](https://matplotlib.org/stable/tutorials/introductory/customizing.html)\n",
        "- [RcParams](https://matplotlib.org/stable/api/matplotlib_configuration_api.html#matplotlib.RcParams)\n",
        "- [Formatting Plotly Axes](https://plotly.com/python/axes/)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoziBOaoyxXq"
      },
      "source": [
        "!pip3 install --upgrade plotly statsmodels\n",
        "!pip3 install kaleido"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8qAk0GGWt7A",
        "outputId": "66f1742d-41fd-4d7c-9698-c51dd87b4c51"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import itertools\n",
        "import functools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from psutil import virtual_memory\n",
        "from pandas import DataFrame, Series\n",
        "from typing import List, Dict\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pytz\n",
        "import datetime as dt\n",
        "import requests\n",
        "import gdown\n",
        "from prettytable import from_csv\n",
        "import sklearn\n",
        "import gzip\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.graph_objects import Figure\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "\n",
        "def timeit(func):\n",
        "    \"\"\"\n",
        "    Decorator for measuring function's running time.\n",
        "    \"\"\"\n",
        "\n",
        "    @functools.wraps(func)\n",
        "    def _timeit_wrapper(*args, **kwargs):\n",
        "        start_time = time.perf_counter()\n",
        "        result = func(*args, **kwargs)\n",
        "        print(\n",
        "            f\"\\nprocessing time of {func.__qualname__}(): {time.perf_counter() - start_time:.5f} seconds\"\n",
        "        )\n",
        "        return result\n",
        "\n",
        "    return _timeit_wrapper\n",
        "\n",
        "\n",
        "def print_now() -> None:\n",
        "    print(\"Local Time = \", dt.datetime.now(pytz.timezone(\"Asia/Taipei\")))\n",
        "\n",
        "\n",
        "def timed_message(*args, **kwargs):\n",
        "    print(*args, **kwargs)\n",
        "    # print('')\n",
        "    print_now()\n",
        "\n",
        "\n",
        "def stamped(func):\n",
        "    @functools.wraps(func)\n",
        "    def do_action(*args, **kwargs):\n",
        "        print(\"\")\n",
        "        print_now()\n",
        "        return func(*args, **kwargs)\n",
        "\n",
        "    return do_action\n",
        "\n",
        "\n",
        "@stamped\n",
        "def tprintf(*args, **kw):\n",
        "    print(*args, **kw)\n",
        "\n",
        "\n",
        "def find_runtime_info() -> None:\n",
        "    print(f'Your runtime is running on {sys.platform}')\n",
        "    ram_gb = virtual_memory().total / 1e9\n",
        "    print('.............has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "    print(f'Python version = {sys.version}')\n",
        "    print(f'scikit-learn version = {sklearn.__version__}')\n",
        "    try:\n",
        "        print(f'TensorFlow version: {tf.__version__}')\n",
        "        devices = pd.DataFrame(tf.config.list_physical_devices())\n",
        "        print('\\nCPU/GPU resource list:\\n')\n",
        "        print(devices.to_markdown())\n",
        "    except NameError:\n",
        "        print('TensorFlow not imported!')\n",
        "        pass\n",
        "    print('')\n",
        "\n",
        "\n",
        "def determine_working_root(project_path: str) -> str:\n",
        "    try:\n",
        "        from google.colab import drive, files\n",
        "\n",
        "        drive.mount(\"/content/drive\")\n",
        "        home_dir = \"/content/drive/My Drive/\"\n",
        "        in_colab = True\n",
        "    except ModuleNotFoundError:\n",
        "        in_colab = False\n",
        "        if sys.platform == \"linux\":\n",
        "            home_dir = \"/mnt/hgfs/\"\n",
        "        else:\n",
        "            home_dir = Path.home()\n",
        "\n",
        "    return os.path.join(home_dir, \"\" if in_colab else \"Google Drive\", project_path)\n",
        "\n",
        "\n",
        "def fetch_file_via_requests(url, save_in_dir):\n",
        "    local_filename = url.split(\"/\")[-1]\n",
        "    # NOTE the stream=True parameter below\n",
        "    output_fpath = os.path.join(save_in_dir, local_filename)\n",
        "    with requests.get(url, stream=True) as r:\n",
        "        r.raise_for_status()\n",
        "        with open(output_fpath, \"wb\") as f:\n",
        "            for chunk in r.iter_content(chunk_size=8192):\n",
        "                if chunk:  # filter out keep-alive new chunks\n",
        "                    f.write(chunk)\n",
        "                    # f.flush()\n",
        "    return output_fpath\n",
        "\n",
        "\n",
        "def dropbox_link(did, fname) -> str:\n",
        "    return \"https://dl.dropboxusercontent.com/s/%s/%s\" % (did, fname)\n",
        "\n",
        "\n",
        "def retrieve_gdrive_file(remote_loc: str, local_name: str) -> None:\n",
        "    download_id = remote_loc[:remote_loc.rfind('/view')].split('/')[-1]\n",
        "    durl = f'https://drive.google.com/u/1/uc?id={download_id:s}&export=download'\n",
        "    gdown.download(durl, local_name, quiet=False)\n",
        "\n",
        "\n",
        "def gdrive_download_url(url: str) -> str:\n",
        "    download_id = url[: url.rfind(\"/view\")].split(\"/\")[-1]\n",
        "    return f\"https://drive.google.com/u/1/uc?id={download_id:s}&export=download\"\n",
        "\n",
        "\n",
        "def retrieve_gdrive_file(remote_loc: str, local_name: str) -> None:\n",
        "    download_id = remote_loc[: remote_loc.rfind(\"/view\")].split(\"/\")[-1]\n",
        "    durl = f\"https://drive.google.com/u/1/uc?id={download_id:s}&export=download\"\n",
        "    gdown.download(durl, local_name, quiet=False)\n",
        "\n",
        "\n",
        "def ungzip(original, uncompressed):\n",
        "    with gzip.open(original, \"rb\") as f_in:\n",
        "        with open(uncompressed, \"wb\") as f_out:\n",
        "            shutil.copyfileobj(f_in, f_out)\n",
        "\n",
        "\n",
        "def print_csv(csv_name: str) -> None:\n",
        "    with open(csv_name) as fp:\n",
        "        mytable = from_csv(fp)\n",
        "    print(mytable)\n",
        "\n",
        "\n",
        "num_of_fwn = lambda df: df.isnull().any().sum()\n",
        "\n",
        "def fwn(df: DataFrame) -> List:\n",
        "    s = df.isnull().any(axis=0)\n",
        "    return s[s==True].index.tolist()\n",
        "\n",
        "def missing_info(df: DataFrame) ->  DataFrame:\n",
        "\n",
        "    features_with_nan = fwn(df)\n",
        "\n",
        "    rate = df[features_with_nan].isnull().mean().sort_values(ascending=False)\n",
        "    sorted_fwn = rate.index.tolist()\n",
        "\n",
        "    missing = df[sorted_fwn].isnull().sum()\n",
        "    unique_value = [len(df[v].unique()) - 1 for v in sorted_fwn]\n",
        "    mode_count = [df[v].value_counts().values[0] for v in sorted_fwn]\n",
        "    return pd.DataFrame(\n",
        "        data={\n",
        "            'missing_rate': (100*rate).round(3),\n",
        "            'missing': missing,\n",
        "            'non_empty': len(df) - missing,\n",
        "            'most_common': mode_count,\n",
        "            'mode': df[sorted_fwn].mode().iloc[0],\n",
        "            'unique': unique_value,\n",
        "            'dtype': [df[x].dtype for x in features_with_nan]\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "def ez_countplot(\n",
        "    df: DataFrame, feature: str, width=600, height=560, font_size=16, template=\"seaborn\"\n",
        ") -> Figure:\n",
        "\n",
        "    d = df[feature].value_counts().sort_index().to_frame()\n",
        "    if template == \"gridon\":\n",
        "        template = \"plotly_white\"\n",
        "\n",
        "    # cindex = [str(x) for x in d.index] if isinstance(d.index[0], np.number) else d.index\n",
        "\n",
        "    fig = px.bar(\n",
        "        d,\n",
        "        x=d.index,\n",
        "        y=feature,\n",
        "        color=feature,\n",
        "        text=[\n",
        "            f\"{d.loc[candidate][0]:d}<br>{(d.loc[candidate][0]/d[feature].sum())*100:.2f}%\"\n",
        "            for candidate in d.index\n",
        "        ],\n",
        "        color_continuous_scale=px.colors.sequential.RdBu_r,\n",
        "    )\n",
        "    # fig.add_hline(y=0, line_color='navy', line_width=1)\n",
        "    fig.update_xaxes(type='category')\n",
        "    fig.update_layout(\n",
        "        template=template,\n",
        "        width=width,\n",
        "        height=height,\n",
        "        font=dict(\n",
        "            family=\"Source Hans TW, monospace\", size=font_size, color=\"RebeccaPurple\"\n",
        "        ),\n",
        "        xaxis_title=feature,\n",
        "        yaxis_title=\"counts/ratiois\",\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "\n",
        "def missing_values_chart(\n",
        "    df: DataFrame, width=800, height=700, font_size=15, template=\"plotly\"\n",
        ") -> Figure:\n",
        "\n",
        "    d = (1 - df.isnull().mean()).to_frame().rename(columns={0: \"filling\"})\n",
        "    dn = (df.isnull().sum()).to_frame().rename(columns={0: \"filling\"})\n",
        "\n",
        "    # colors = px.colors.sequential.Redor\n",
        "    # fig = go.Figure()\n",
        "    # fig.add_trace(go.Bar(\n",
        "    #     y=d.index, x=d.filling, orientation='h',\n",
        "    #     marker_color=px.colors.sequential.RdBu_r,\n",
        "    #     textposition='auto',\n",
        "    #     text=[f'{d.loc[e][0]*100:.1f}%' for e in d.index]))\n",
        "\n",
        "    fig = px.bar(\n",
        "        d,\n",
        "        x=\"filling\",\n",
        "        color=d.columns[0],\n",
        "        orientation=\"h\",\n",
        "        text=[f\"{e:s} | {dn.loc[e][0]:d} / {d.loc[e][0]*100:.1f}%\" for e in d.index],\n",
        "        color_continuous_scale=colors,\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        width=width,\n",
        "        height=height,\n",
        "        template=template,\n",
        "        yaxis_title=\"Features\",\n",
        "        #   xaxis_tickangle=25,\n",
        "        font_size=font_size,\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "\n",
        "output_fig = lambda name: plt.savefig(f\"./{name}.png\", dpi=300)\n",
        "\n",
        "REPO = \"https://raw.githubusercontent.com/profundo-lab/bagel/main/\"\n",
        "REPO2 = \"https://raw.githubusercontent.com/imrchen/aprendiendo/master/data/\"\n",
        "\n",
        "find_runtime_info()\n",
        "\n",
        "tprintf(\"lección uno: helper functions loaded\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime is running on linux\n",
            ".............has 13.6 gigabytes of available RAM\n",
            "\n",
            "Python version = 3.7.11 (default, Jul  3 2021, 18:01:19) \n",
            "[GCC 7.5.0]\n",
            "scikit-learn version = 0.22.2.post1\n",
            "TensorFlow not imported!\n",
            "\n",
            "\n",
            "Local Time =  2021-08-06 13:19:13.100518+08:00\n",
            "lección uno: helper functions loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDwaaeRUPMso",
        "outputId": "92b345b2-3d01-4d4c-9030-e6460d40cc86"
      },
      "source": [
        "def find_runtime_info() -> None:\n",
        "    print(f'Your runtime is running on {sys.platform}')\n",
        "    ram_gb = virtual_memory().total / 1e9\n",
        "    print('.............has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "    print(f'Python version = {sys.version}')\n",
        "    print(f'scikit-learn version = {sklearn.__version__}')\n",
        "    try:\n",
        "        print(f'TensorFlow version: {tf.__version__}')\n",
        "        devices = pd.DataFrame(tf.config.list_physical_devices())\n",
        "        print('\\nCPU/GPU resource list:\\n')\n",
        "        print(devices.to_markdown())\n",
        "    except NameError:\n",
        "        print('TensorFlow not imported!')\n",
        "        pass\n",
        "    print('')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime is running on linux\n",
            ".............has 13.6 gigabytes of available RAM\n",
            "\n",
            "Python version = 3.7.11 (default, Jul  3 2021, 18:01:19) \n",
            "[GCC 7.5.0]\n",
            "scikit-learn version = 0.22.2.post1\n",
            "TensorFlow not imported!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGbd2lQfzXEC",
        "outputId": "6e25f532-0857-42e5-c8a9-1e458c9e64df"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIf3wq1Tyyx6",
        "outputId": "413f96b0-209d-454a-80dc-49bf01719b5a"
      },
      "source": [
        "!free -h --si | awk  '/Mem:/{print $2}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13G\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUmYoDSn5Nwd",
        "outputId": "cf524752-c71b-4e67-bb6f-4a53154b2a6b"
      },
      "source": [
        "!lscpu | grep 'CPU(s)'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU(s):              2\n",
            "On-line CPU(s) list: 0,1\n",
            "NUMA node0 CPU(s):   0,1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKDUJrnnzAzZ",
        "outputId": "23118737-a9a4-46cb-ec1a-666bd873e3f6"
      },
      "source": [
        "!lscpu "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Architecture:        x86_64\n",
            "CPU op-mode(s):      32-bit, 64-bit\n",
            "Byte Order:          Little Endian\n",
            "CPU(s):              2\n",
            "On-line CPU(s) list: 0,1\n",
            "Thread(s) per core:  2\n",
            "Core(s) per socket:  1\n",
            "Socket(s):           1\n",
            "NUMA node(s):        1\n",
            "Vendor ID:           GenuineIntel\n",
            "CPU family:          6\n",
            "Model:               63\n",
            "Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "Stepping:            0\n",
            "CPU MHz:             2299.998\n",
            "BogoMIPS:            4599.99\n",
            "Hypervisor vendor:   KVM\n",
            "Virtualization type: full\n",
            "L1d cache:           32K\n",
            "L1i cache:           32K\n",
            "L2 cache:            256K\n",
            "L3 cache:            46080K\n",
            "NUMA node0 CPU(s):   0,1\n",
            "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5tl_Luxrcu5"
      },
      "source": [
        "## Directory Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLysD6RYrjsI"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "project_root = 'aprendizaje'\n",
        "project = 'contribution'\n",
        "\n",
        "working_root = determine_working_root(project_root)\n",
        "data_dir = os.path.join(working_root, 'data', project)\n",
        "figure_dir = os.path.join(working_root, 'figure', project)\n",
        "predict_dir = os.path.join(working_root, 'prediction', project)\n",
        "train_source = os.path.join(data_dir, 'train.csv')\n",
        "test_source = os.path.join(data_dir, 'test.csv')\n",
        "\n",
        "output_fig = lambda name: plt.savefig(\n",
        "    os.path.join(figure_dir, name + '.png'),\n",
        "    dpi=300\n",
        ")\n",
        "print(f'project code -> {project}')\n",
        "print(f'data storage location -> {data_dir}')\n",
        "timed_message('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nORLbFIerXUE"
      },
      "source": [
        "## 載入中文字型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGcuM1_AqxFK",
        "outputId": "2e5e1a5a-49d2-46fd-a937-295c4f171158"
      },
      "source": [
        "%%time \n",
        "\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "from matplotlib.font_manager import FontProperties\n",
        "\n",
        "\n",
        "def determine_font_dest() -> str:\n",
        "    mpl_path = mpl.__file__\n",
        "    return mpl_path[:mpl_path.rfind('/')] + '/mpl-data/fonts/ttf'\n",
        "\n",
        "\n",
        "# 載入中文字型\n",
        "#\n",
        "\n",
        "lanting_source = 'LanTingSong.ttf'           # plt.rcParams['font.sans-serif'] = ['FZLanTingSong']\n",
        "hans_source = 'SourceHanSerifTW-Regular.ttf' # plt.rcParams['font.sans-serif'] = ['Source Han Serif TW']\n",
        "hei_source = 'TaipeiSansTCBeta-Regular.ttf'  # plt.rcParams['font.sans-serif'] = ['Taipei Sans TC Beta']\n",
        "genryu_source = 'GenRyuMin-R.ttc'            # plt.rcParams['font.sans-serif'] = ['GenRyuMin TW']\n",
        "\n",
        "font_dest = determine_font_dest()\n",
        "\n",
        "fonts = [\n",
        "    ['vj0eq732aq36tto', 'SourceHanSerifTW-Regular.ttf'],\n",
        "    ['t38q9m4gdaco9qz', 'LanTingSong.ttf'],\n",
        "    ['w7yvxtou1x1dmkx', 'GenRyuMin-R.ttc'],\n",
        "    ['1nm46fy1sahq1i5', 'TaipeiSansTCBeta-Regular.ttf']\n",
        "]\n",
        "\n",
        "for each in fonts:\n",
        "    fetch_file_via_requests(dropbox_link(each[0], each[1]), font_dest)\n",
        "\n",
        "song = FontProperties(fname=os.path.join(font_dest, hans_source))\n",
        "hei = FontProperties(fname=os.path.join(font_dest, hei_source))\n",
        "genruy = FontProperties(fname=os.path.join(font_dest, genryu_source))\n",
        "\n",
        "tprintf('載入中文字型')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Local Time =  2021-07-21 18:46:37.097162+08:00\n",
            "載入中文字型\n",
            "CPU times: user 299 ms, sys: 229 ms, total: 528 ms\n",
            "Wall time: 4.76 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HEWvdef2Z-u"
      },
      "source": [
        "## Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8JmLjWm2crl"
      },
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "\n",
        "\n",
        "num_of_fwn = lambda df: df.isnull().any().sum()\n",
        "\n",
        "def fwn(df: DataFrame) -> List:\n",
        "    s = df.isnull().any(axis=0)\n",
        "    return s[s==True].index.tolist()\n",
        "\n",
        "def missing_info(df: DataFrame) ->  DataFrame:\n",
        "\n",
        "    features_with_nan = fwn(df)\n",
        "\n",
        "    rate = df[features_with_nan].isnull().mean().sort_values(ascending=False)\n",
        "    sorted_fwn = rate.index.tolist()\n",
        "\n",
        "    missing = df[sorted_fwn].isnull().sum()\n",
        "    unique_value = [len(df[v].unique()) - 1 for v in sorted_fwn]\n",
        "    mode_count = [df[v].value_counts().values[0] for v in sorted_fwn]\n",
        "    return pd.DataFrame(\n",
        "        data={\n",
        "            'missing_rate': (100*rate).round(3),\n",
        "            'missing': missing,\n",
        "            'non_empty': len(df) - missing,\n",
        "            'most_common': mode_count,\n",
        "            'mode': df[sorted_fwn].mode().iloc[0],\n",
        "            'unique': unique_value,\n",
        "            'dtype': [df[x].dtype for x in features_with_nan]\n",
        "        }\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRrokW6YsATH"
      },
      "source": [
        "## Regression Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p42qTIObsEZL"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from numpy import ndarray\n",
        "\n",
        "\n",
        "def ols_fit(x_vector: np.array, y_vector: np.array, *args, **kw):\n",
        "    #\n",
        "    # df['constant'] = 1\n",
        "    # model = sm.OLS(endog=df['y'], exog=[np.array(df['constant', 'x'])\n",
        "    #\n",
        "    x_vec = sm.add_constant(x_vector)       # adding a constant\n",
        "    return sm.OLS(endog=y_vector, exog=x_vec, *args, **kw).fit()\n",
        "\n",
        "\n",
        "def polynomial_approx(predictor: ndarray, target: ndarray, degree: int, *args, **kwargs):\n",
        "    if predictor.ndim == 1:\n",
        "        x = predictor.reshape(-1, 1)\n",
        "    poly_features = PolynomialFeatures(degree).fit_transform(x)\n",
        "    model = sm.OLS(target, poly_features, *args, **kwargs).fit()\n",
        "    return model\n",
        "\n",
        "\n",
        "def polyfit_wrapper(xvec, yvec, degree = 3, xdomain = None):\n",
        "    p = np.polyfit(xvec.flatten(), yvec.flatten(), degree)\n",
        "    if xdomain is None:\n",
        "        xdomain = np.linspace( min(xvec.flatten()), max(xvec.flatten()), 100 )\n",
        "\n",
        "    return np.polyval(p, xdomain), \n",
        "\n",
        "def polynomial_approximation(x, y, deg, x_domain=None):\n",
        "\n",
        "    the_model = make_pipeline(PolynomialFeatures(deg), LinearRegression())\n",
        "    if x.ndim == 1:\n",
        "        x = x[:, np.newaxis]\n",
        "    the_model.fit(x, y)\n",
        "    if x_domain is None:\n",
        "        x_domain = x\n",
        "    predicted_values = the_model.predict(x_domain)\n",
        "    return the_model, predicted_values, r2_score(y, the_model.predict(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bqeeCGCjME0"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP2nXxkMNDfi"
      },
      "source": [
        "- [Scikit-learn: How to obtain True Positive, True Negative, False Positive and False Negative](https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fa)\n",
        "\n",
        "![](https://i.stack.imgur.com/AuTKP.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DteGOO30jPdG",
        "outputId": "119c3c1b-8e1d-44b3-dd21-dbdf8688bcf3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy import ndarray\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from matplotlib.axes import Axes\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "def confusion_counters(y_true: ndarray, y_pred: ndarray) -> tuple:\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    FP = cm.sum(axis=0) - np.diag(cm)  \n",
        "    FN = cm.sum(axis=1) - np.diag(cm)\n",
        "    TP = np.diag(cm)\n",
        "    TN = cm.sum() - (FP + FN + TP)\n",
        "\n",
        "    # # Sensitivity, hit rate, recall, or true positive rate\n",
        "    # TPR = TP/(TP+FN)\n",
        "    # # Specificity or true negative rate\n",
        "    # TNR = TN/(TN+FP) \n",
        "    # # Precision or positive predictive value\n",
        "    # PPV = TP/(TP+FP)\n",
        "    # # Negative predictive value\n",
        "    # NPV = TN/(TN+FN)\n",
        "    # # Fall out or false positive rate\n",
        "    # FPR = FP/(FP+TN)\n",
        "    # # False negative rate\n",
        "    # FNR = FN/(TP+FN)\n",
        "    # # False discovery rate\n",
        "    # FDR = FP/(TP+FP)\n",
        "\n",
        "    # len(FP) = numer of classes\n",
        "    return np.array([TP, FP, FN, TN]).reshape(4, len(FP))\n",
        "\n",
        "\n",
        "def class_confusion_matrix(y_true, y_pred, class_pos=1) -> ndarray:\n",
        "    cm_data = confusion_counters(y_true, y_pred)\n",
        "    num_classes = cm_data.shape[1]\n",
        "    return cm_data[:, class_pos].reshape(num_classes, num_classes)\n",
        "\n",
        "\n",
        "def plot_multilabel_cm(y_true, y_pred, classes=\"auto\", figsize=(6, 5)) -> Axes:\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    bscm = cm.copy()\n",
        "    for i in range(cm.shape[0]):\n",
        "        bscm[:, i]= cm[i, :]\n",
        "\n",
        "    _, ax = plt.subplots(figsize=figsize, dpi=150)\n",
        "    sns.heatmap(\n",
        "        bscm, annot=True, fmt='d', \n",
        "        xticklabels = classes,\n",
        "        yticklabels = classes,\n",
        "        ax=ax)\n",
        "\n",
        "    ax.set_xlabel(\"Actual Classes\")\n",
        "    ax.set_ylabel(\"Predicted Classes\")\n",
        "    return ax\n",
        "\n",
        "\n",
        "tprintf(\"confusion matrix tools loaded\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Local Time =  2021-07-23 12:53:13.319303+08:00\n",
            "confusion matrix tools loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEZgtLMpsqV6"
      },
      "source": [
        "## comparar models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5xpgNKUstvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19056d63-e41c-4f06-8375-8d707b31a990"
      },
      "source": [
        "from numpy import ndarray\n",
        "from pandas import DataFrame\n",
        "from sklearn.utils import resample\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas import DataFrame\n",
        "from numpy import ndarray\n",
        "from collections import defaultdict\n",
        "import itertools\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
        "from imblearn.pipeline import make_pipeline\n",
        "\n",
        "\n",
        "def resample_data(original_data: DataFrame, feature: str, ratio=1.) -> DataFrame:\n",
        "    items = defaultdict()\n",
        "\n",
        "    for e in original_data[feature].unique():\n",
        "        items[e] = original_data[original_data[feature] == e]\n",
        "\n",
        "    minor_item = original_data[feature].value_counts().sort_values(ascending=False).index[1]\n",
        "    major_item = original_data[feature].value_counts().sort_values(ascending=False).index[0]\n",
        "    mode_count = original_data[feature].value_counts().sort_values(ascending=False)[0]\n",
        "    # minor_count = original_data[feature].value_counts().sort_values(ascending=False)[1]\n",
        "    resample_count = int(mode_count * ratio)\n",
        "\n",
        "    df_up = resample(\n",
        "        items[minor_item],\n",
        "        replace=True,\n",
        "        n_samples=resample_count,\n",
        "        random_state=0)\n",
        "\n",
        "    return pd.concat([items[major_item], df_up], axis=0, ignore_index=True)\n",
        "\n",
        "    \n",
        "@timeit\n",
        "def analizar_model(\n",
        "    estimator, train_set: DataFrame, test_set: DataFrame, target: str\n",
        ") -> ndarray:\n",
        "    train_x = train_set.drop([target], axis=1)\n",
        "    train_y = train_set.response\n",
        "    test_x = test_set.drop([target], axis=1)\n",
        "    test_y = test_set.response\n",
        "\n",
        "    estimator.fit(train_x, train_y)\n",
        "    y_pred = estimator.predict(test_x)\n",
        "    return np.array(precision_recall_fscore_support(test_y, y_pred)).reshape(1, -1)\n",
        "\n",
        "\n",
        "@timeit\n",
        "def comparar_models(\n",
        "    model_collections: dict, train_data, train_labels, k=5, scoring=\"accuracy\"\n",
        ") -> DataFrame:\n",
        "\n",
        "    seed = 0\n",
        "    data_fold = StratifiedKFold(n_splits=k, random_state=seed, shuffle=True)\n",
        "    results = []\n",
        "\n",
        "    for name in model_collections.keys():\n",
        "        cv_results = cross_val_score(\n",
        "            model_collections[name],\n",
        "            train_data,\n",
        "            train_labels,\n",
        "            cv=data_fold,\n",
        "            scoring=scoring,\n",
        "        )\n",
        "        results.append(cv_results)\n",
        "        # print(f\"{name:s}: {cv_results.mean():.4f} {cv_results.std():.4f}\")\n",
        "\n",
        "    d = pd.DataFrame(\n",
        "        data=np.array(results), columns=np.arange(1, len(cv_results) + 1, 1).astype(str)\n",
        "    )\n",
        "    d[\"model\"] = model_collections.keys()\n",
        "    d.set_index([\"model\"], drop=True, inplace=True)\n",
        "    return d\n",
        "\n",
        "\n",
        "@timeit\n",
        "def comparar_recall(\n",
        "    model_collections: dict,\n",
        "    train_data: DataFrame,\n",
        "    train_labels: DataFrame,\n",
        "    test_data: DataFrame,\n",
        "    test_labels: DataFrame,\n",
        "    scoring=\"accuracy\",\n",
        ") -> DataFrame:\n",
        "\n",
        "    seed = 0\n",
        "    # data_fold = StratifiedKFold(n_splits=k, random_state=seed, shuffle=True)\n",
        "    results = []\n",
        "\n",
        "    for name in model_collections.keys():\n",
        "        model = model_collections[name]\n",
        "        model.fit(train_data, train_labels)\n",
        "\n",
        "        y_train_pred = model.predict(train_data)\n",
        "        _, rtrain, _, _ = precision_recall_fscore_support(\n",
        "            train_labels, y_train_pred, zero_division=1\n",
        "        )\n",
        "        y_pred = model.predict(test_data)\n",
        "        p, rtest, f, s = precision_recall_fscore_support(\n",
        "            test_labels, y_pred, zero_division=1\n",
        "        )\n",
        "        acc = accuracy_score(test_labels, y_pred)\n",
        "\n",
        "        # combined = np.array([p, rtrain, rtest, f]).flatten()\n",
        "        # combined = np.concatenate([np.array([acc]), combined], axis=0)\n",
        "\n",
        "        nl = [[acc], p, rtrain, rtest, f]\n",
        "        results.append(list(itertools.chain(*nl)))\n",
        "        # results.append(combined)\n",
        "\n",
        "    # print('before constructing dataframe')\n",
        "\n",
        "    d = pd.DataFrame(\n",
        "        data=np.array(results),\n",
        "        columns=[\n",
        "            \"accuracy\",\n",
        "            \"p(0)\",\n",
        "            \"p(1)\",\n",
        "            \"r(0)\",\n",
        "            \"r(1)\",\n",
        "            \"rt(0)\",\n",
        "            \"rt(1)\",\n",
        "            \"f(0)\",\n",
        "            \"f(1)\",\n",
        "        ],\n",
        "    )\n",
        "    d[\"model\"] = model_collections.keys()\n",
        "    d.set_index([\"model\"], drop=True, inplace=True)\n",
        "    return d\n",
        "\n",
        "tprintf(\"comparar_model defined\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Local Time =  2021-07-22 18:15:01.328080+08:00\n",
            "comparar_model defined\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning:\n",
            "\n",
            "The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning:\n",
            "\n",
            "The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qreAeznxrrY8"
      },
      "source": [
        "## 如何下載 Colab VM 硬碟檔案"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBn5YC6vryJi"
      },
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "for f in os.listdir('./'):\n",
        "    if os.path.isdir(f) or f.rfind('.png') < 0:\n",
        "        continue\n",
        "    files.download(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdJYlBOgtmjS"
      },
      "source": [
        "## Avialable scoring metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kwh3ZXBst336"
      },
      "source": [
        "\n",
        "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CTAVWL2ttU7"
      },
      "source": [
        "import sklearn.metrics\n",
        "for x in sklearn.metrics.SCORERS.keys():\n",
        "    print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHroM3hhtxST",
        "outputId": "3f2a4a65-7f27-4def-c1dc-6e41f8825a1a"
      },
      "source": [
        "sklearn.metrics.SCORERS.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4KCN_pSftTu"
      },
      "source": [
        "## GPU info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnIetX3oznG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c28063ca-3161-404a-b0d7-07320a60b1cd"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, \n",
            "and then re-execute this cell.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdSbwf1BgeKT"
      },
      "source": [
        "# ✅ Here we go...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmTOBJSvqy1w"
      },
      "source": [
        "# End of Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DICuRiF0fy8L"
      },
      "source": [
        "## 回收暫存區"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeIB2O2j4okv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 42
        },
        "outputId": "0e500a02-d94b-420d-e12b-9a5b5b765388"
      },
      "source": [
        "device = torch.device(\n",
        "    'cuda' if torch.cuda.is_available() else 'cpu'\n",
        ")\n",
        "print('Torch Device set to -->', device)\n",
        "\n",
        "#Additional Info when using cuda\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Torch Device set to --> cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNv76Uwm4tD4"
      },
      "source": [
        "#Additional Info when using cuda\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBORUtvj1sa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56b49685-c9c9-42ef-b149-e614dff146f0"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import seaborn as sns\n",
        "import statsmodels\n",
        "import torch\n",
        "import torchvision\n",
        "import mlxtend\n",
        "import lightgbm\n",
        "import xgboost\n",
        "\n",
        "print(f'numpy version = {np.__version__}')\n",
        "print(f'pandas version = {pd.__version__}')\n",
        "print(f'scikit-learn version = {sklearn.__version__}')\n",
        "print(f'mlxtend version = {mlxtend.__version__}')\n",
        "print(f'xgboost version = {xgboost.__version__}')\n",
        "print(f'lightgbm version = {lightgbm.__version__}')\n",
        "print(f'statsmodel version = {statsmodels.__version__}')\n",
        "print(f'PyTorch version = {torch.__version__}')\n",
        "print(f'TorchVision version = {torchvision.__version__}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "numpy version = 1.19.5\n",
            "pandas version = 1.1.5\n",
            "scikit-learn version = 0.22.2.post1\n",
            "mlxtend version = 0.14.0\n",
            "xgboost version = 0.90\n",
            "lightgbm version = 2.2.3\n",
            "statsmodel version = 0.10.2\n",
            "PyTorch version = 1.9.0+cu102\n",
            "TorchVision version = 0.10.0+cu102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0bGTWHFuBlF"
      },
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpCse5zAfPlk"
      },
      "source": [
        "# End......"
      ]
    }
  ]
}